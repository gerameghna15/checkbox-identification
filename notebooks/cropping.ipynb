{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6f286e",
   "metadata": {},
   "source": [
    "# Checkbox Cropping Pipeline\n",
    "\n",
    "This notebook implements the checkbox cropping pipeline used in this project.\n",
    "The pipeline extracts checkbox regions from document images using COCO bounding\n",
    "box annotations.\n",
    "\n",
    "The same cropping logic was used to generate:\n",
    "- `cropped_checkboxes_binary` (full cropped dataset)\n",
    "- `cropped_checkboxes_binary_small` (reduced and balanced subset)\n",
    "\n",
    "The reduced dataset was created by applying an additional sampling constraint\n",
    "after cropping. No changes were made to the cropping logic itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47ebe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Resetting FULL output folder (safe overwrite)...\n",
      "\n",
      "Processing split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4403/4403 [00:19<00:00, 228.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4403 crops for train\n",
      "Class distribution: {'unchecked': 2374, 'checked': 2029}\n",
      "\n",
      "Processing split: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 978/978 [00:04<00:00, 240.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 978 crops for valid\n",
      "Class distribution: {'unchecked': 451, 'checked': 527}\n",
      "\n",
      "Processing split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 714/714 [00:03<00:00, 236.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 714 crops for test\n",
      "Class distribution: {'checked': 233, 'unchecked': 481}\n",
      "\n",
      "âœ… FULL binary dataset created successfully.\n",
      "ðŸ“ Output saved at: ../processed/cropped_checkboxes_binary\n",
      "\n",
      "ðŸ§¹ Resetting SMALL output folder (safe overwrite)...\n",
      "\n",
      "ðŸ“Œ Creating reduced dataset (balanced)...\n",
      "\n",
      "TRAIN reduced distribution: {'checked': 500, 'unchecked': 500}\n",
      "\n",
      "VALID reduced distribution: {'checked': 150, 'unchecked': 150}\n",
      "\n",
      "TEST reduced distribution: {'checked': 200, 'unchecked': 200}\n",
      "\n",
      "âœ… SMALL binary dataset created successfully.\n",
      "ðŸ“ Output saved at: ../processed/cropped_checkboxes_binary_small\n",
      "Final limits used: {'train': 500, 'valid': 150, 'test': 200}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# =========================\n",
    "# CONFIG (BINARY ONLY)\n",
    "# =========================\n",
    "BASE_DIR = \"../data/raw/Checkbox.v7i.coco\"\n",
    "\n",
    "OUTPUT_DIR_FULL  = \"../data/processed/cropped_checkboxes_binary\"\n",
    "OUTPUT_DIR_SMALL = \"../data/processed/cropped_checkboxes_binary_small\"\n",
    "\n",
    "SPLITS = [\"train\", \"valid\", \"test\"]\n",
    "CLASSES = [\"checked\", \"unchecked\"]\n",
    "\n",
    "TARGET_SIZE = 224\n",
    "PADDING_RATIO = 0.25\n",
    "\n",
    "# ---- reduce sizes (balanced) ----\n",
    "LIMITS = {\n",
    "    \"train\": 500,\n",
    "    \"valid\": 150,\n",
    "    \"test\":  200\n",
    "}\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# =========================\n",
    "# RESET OUTPUT DIR (SAFE OVERWRITE)\n",
    "# =========================\n",
    "OVERWRITE = True  # set to False to prevent deletion\n",
    "def reset_output_dir(root_dir):\n",
    "    if os.path.exists(root_dir):\n",
    "        if not OVERWRITE:\n",
    "            raise RuntimeError(\n",
    "                f\"{root_dir} already exists. Set OVERWRITE=True to recreate it.\"\n",
    "            )\n",
    "        shutil.rmtree(root_dir)\n",
    "    for split in SPLITS:\n",
    "        for cls in CLASSES:\n",
    "            os.makedirs(os.path.join(root_dir, split, cls), exist_ok=True)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# STEP 1: CREATE FULL CROPPED DATASET\n",
    "# =========================\n",
    "print(\"Resetting FULL output folder (safe overwrite)...\")\n",
    "reset_output_dir(OUTPUT_DIR_FULL)\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"\\nProcessing split: {split}\")\n",
    "\n",
    "    image_dir = os.path.join(BASE_DIR, split)\n",
    "    ann_file = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "\n",
    "    with open(ann_file, \"r\") as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    image_id_to_name = {img[\"id\"]: img[\"file_name\"] for img in coco[\"images\"]}\n",
    "    category_id_to_name = {cat[\"id\"]: cat[\"name\"] for cat in coco[\"categories\"]}\n",
    "\n",
    "    counter = 0\n",
    "    class_counter = Counter()\n",
    "\n",
    "    for ann in tqdm(coco[\"annotations\"], desc=f\"Cropping {split}\"):\n",
    "        class_name = category_id_to_name[ann[\"category_id\"]]\n",
    "\n",
    "        if class_name not in CLASSES:\n",
    "            continue\n",
    "\n",
    "        img_id = ann[\"image_id\"]\n",
    "        x, y, w, h = map(int, ann[\"bbox\"])\n",
    "\n",
    "        # Safety clamps\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        w = max(1, w)\n",
    "        h = max(1, h)\n",
    "\n",
    "        img_path = os.path.join(image_dir, image_id_to_name[img_id])\n",
    "\n",
    "        if os.path.basename(img_path).startswith(\".\"):\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        H, W = image.shape[:2]\n",
    "\n",
    "        # Padding around bbox\n",
    "        pad_x = int(w * PADDING_RATIO)\n",
    "        pad_y = int(h * PADDING_RATIO)\n",
    "\n",
    "        x1 = max(0, x - pad_x)\n",
    "        y1 = max(0, y - pad_y)\n",
    "        x2 = min(W, x + w + pad_x)\n",
    "        y2 = min(H, y + h + pad_y)\n",
    "\n",
    "        crop = image[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        crop = cv2.resize(crop, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        out_name = f\"{split}_{img_id}_{counter}.png\"\n",
    "        out_path = os.path.join(OUTPUT_DIR_FULL, split, class_name, out_name)\n",
    "        cv2.imwrite(out_path, crop)\n",
    "\n",
    "        counter += 1\n",
    "        class_counter[class_name] += 1\n",
    "\n",
    "    print(f\"Saved {counter} crops for {split}\")\n",
    "    print(\"Class distribution:\", dict(class_counter))\n",
    "\n",
    "print(\"\\nâœ… FULL binary dataset created successfully.\")\n",
    "print(f\"ðŸ“ Output saved at: {OUTPUT_DIR_FULL}\")\n",
    "\n",
    "# =========================\n",
    "# STEP 2: CREATE SMALL BALANCED DATASET\n",
    "# =========================\n",
    "print(\"\\nðŸ§¹ Resetting SMALL output folder (safe overwrite)...\")\n",
    "reset_output_dir(OUTPUT_DIR_SMALL)\n",
    "\n",
    "def list_images(folder):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if (not f.startswith(\".\")) and f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ]\n",
    "\n",
    "print(\"\\nCreating reduced dataset (balanced)...\")\n",
    "\n",
    "# Reduction step:\n",
    "# Limits the number of cropped samples per class per split\n",
    "# Used only for constructing the reduced dataset\n",
    "\n",
    "for split in SPLITS:\n",
    "    per_class_limit = LIMITS[split]\n",
    "    split_counter = Counter()\n",
    "\n",
    "    for cls in CLASSES:\n",
    "        src_folder = os.path.join(OUTPUT_DIR_FULL, split, cls)\n",
    "        dst_folder = os.path.join(OUTPUT_DIR_SMALL, split, cls)\n",
    "\n",
    "        files = list_images(src_folder)\n",
    "        random.shuffle(files)\n",
    "\n",
    "        keep_n = min(per_class_limit, len(files))\n",
    "        selected = files[:keep_n]\n",
    "\n",
    "        for path in selected:\n",
    "            shutil.copy2(path, os.path.join(dst_folder, os.path.basename(path)))\n",
    "\n",
    "        split_counter[cls] = keep_n\n",
    "\n",
    "    print(f\"\\n{split.upper()} reduced distribution:\", dict(split_counter))\n",
    "\n",
    "print(\"\\nâœ… SMALL binary dataset created successfully.\")\n",
    "print(f\"ðŸ“ Output saved at: {OUTPUT_DIR_SMALL}\")\n",
    "print(\"Final limits used:\", LIMITS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
